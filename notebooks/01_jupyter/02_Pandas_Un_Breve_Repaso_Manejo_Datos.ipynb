{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Datos\n",
    "\n",
    "[`pandas`](https://pandas.pydata.org) es una librería que nos permite consultar y modificar datos estructurados y etiquetados, que funciona como una capa de abstracción sobre `NumPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos librerias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructuras de datos\n",
    "\n",
    "En `pandas` podemos encontrar dos estructuras de datos:\n",
    "\n",
    "* [`Series`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html): para datos de una dimensión. Sería similar a una lista de elementos.\n",
    "* [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html): para datos de dos dimensiones. En este caso, sería equivalente a una tabla de una base de datos o una hoja de cálculo. Esta estructura es la más utilizada en `pandas`.\n",
    "\n",
    "\n",
    "Internamente, las columnas de un `DataFrame` están formadas por objetos `Series`. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Carga de datos\n",
    "\n",
    "Mediante `pandas` podemos cargar datos desde ficheros de texto como CSV, Microsoft Excel, HTML, bases de datos y HDF5:\n",
    "\n",
    "* `pandas.read_csv`\n",
    "* `pandas.read_excel`\n",
    "* `pandas.read_html`\n",
    "* `pandas.read_sql`\n",
    "* `pandas.read_hdf5`\n",
    "\n",
    "En este tutorial utilizaremos la lectura de ficheros de texto: [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "Vamos a cargar el conjunto de datos de las flores Iris (https://es.wikipedia.org/wiki/Iris_flor_conjunto_de_datos), que es muy utilizado en las introducciones a Data Science. \n",
    "\n",
    "Este conjunto de datos contiene información sobre las dimensiones de tipos de flores Iris y está compuesto por las siguientes columnas:\n",
    "\n",
    "* **sepal length (cm)**: largo de sépalo en centímetros.\n",
    "* **sepal width (cm)**: ancho de sépalo en centímetros.\n",
    "* **petal length (cm)**: largo de pétalo en centímetros.\n",
    "* **petal width (cm)**: ancho de pétalo en centímetros.\n",
    "* **species**: tipo de flor Iris. En el conjunto de datos tenemos tres tipos: Versicolor, Setosa y Virginica.\n",
    "\n",
    "¿Qué es un sépalo?\n",
    "![Pétalo vs sépalo](./imges/04_01_pet_sep.png)\n",
    "\n",
    "Iris Versicolor\n",
    "![Verisocolor](./imges/04_02_iris_versicolor.png)\n",
    "\n",
    "Iris Setosa \n",
    "![Setosa](./imges/04_03_iris_setosa.png)\n",
    "\n",
    "Iris Virginica\n",
    "![Viriginica](./imges/04_04_iris_virginica.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos del fichero CSV y creamos un DataFrame\n",
    "df = pd.read_csv('./data/04_01_iris.csv')\n",
    "\n",
    "# Imprimimos los datos cargados: las primeras 15 filas\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración básica de los datos\n",
    "\n",
    "En este apartado utilizaremos algunos métodos que nos permiten hacernos una idea de la información que contiene nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultamos el total de elementos no vacíos, la media, desviación estándar, el valor mínimo, \n",
    "# los percentiles 25, 50 (mediana), 75 y el valor máximo\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultamos el tipo de estructura que pandas está utilizando, \n",
    "# el total de registros, el tipo de datos de cada columna y la memoria utilizada\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos saber las dimensiones de nuestro DataFrame de la siguiente forma\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si lo necesitamos, podemos transformar los datos a un ndarray fácilmente\n",
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetas de filas y columnas\n",
    "\n",
    "`pandas` permite etiquetar fácilmente las columnas y filas de los `DataFrame` con los nombres que deseemos. En el caso de Series, tendremos únicamente etiquetas para las filas.\n",
    "\n",
    "Por ejemplo, veamos las etiquetas que tenemos en nuestro `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra las etiquetas o nombres de las filas\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destacar que en todos los casos obtenemos objetos de la clase Index. Esta clase contiene en realidad un ndarray, que podemos obtener utlizando también values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el ndarray correspondiente al nombre de las filas\n",
    "df.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo deseamos, podemos cambiar los nombres de las filas y columnas de forma muy sencilla. Veamos cómo podemos hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el nombre de las filas asignando el nuevo nombre directamente a index:\n",
    "df.index = np.arange(500, 650) # Crea un ndarray desde el número 500 hasta el 649, 150 elementos en total\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y para cambiar el nombre de las columnas lo hacemos de una forma muy similar\n",
    "df.columns = ['A', 'B', 'C', 'D', 'E']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos de nuevo el DataFrame original para seguir con el notebook\n",
    "df = pd.read_csv('./data/04_01_iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexación mediante `Series` de `boolean`\n",
    "\n",
    "1\n",
    "En `pandas` también es posible indexar datos mediante un objeto `Series` de tipo `boolean`, es decir, una lista de valores verdadero o falso. Esta lista actúa como un filtro sobre todas las filas del `DataFrame` y se nos devuelve únicamente las filas con valor verdadero.\n",
    "2\n",
    "​\n",
    "3\n",
    "Este objeto puede crearse muy fácilmente a partir de operadores de comparación o mediante métodos de `pandas` que los devuelven directamente. Vamos a ver algunos ejemplos para comprender cómo funciona.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si queremos consultar todas las filas que son de las especie virginica podemos hacerlo del siguiente modo:\n",
    "\n",
    "cond = df['species'] == 'virginica' # Escribimos la condición y la guardamos en una variable\n",
    "\n",
    "cond.sample(20, random_state=5) # Imprimimos una selección aleatoria de la lista de valores para ver qué contiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y ahora para filtrar, simplemente debemos utilizar la lista de valores verdadero y falso \n",
    "# directamente en el DataFrame de la siguiente forma:\n",
    "df[cond].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos filtrar por más de una condición, como por ejemplo:\n",
    "\n",
    "cond1 = df['species'] == 'virginica'\n",
    "cond2 = df['sepal width (cm)'] <= 2.5\n",
    "\n",
    "df[cond1 & cond2] # Filtra por ambas condiciones a la vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otro ejemplo de filtro por más de una condición:\n",
    "\n",
    "cond1 = df['species'] == 'virginica'\n",
    "cond2 = df['sepal width (cm)'] <= 2.5\n",
    "cond3 = df['petal width (cm)'] >= 2.2\n",
    "\n",
    "df[cond1 & (cond2 | cond3)].head() # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación, modificación y borrado de filas y columnas\n",
    "\n",
    "En este apartado veremos cómo podemos añadir nuevos datos al `DataFrame` que hemos cargado y modificar o borrar su contenido ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es posible crear nuevas columnas fácilmente a partir de las existentes, por ejemplo, mediante\n",
    "# operaciones aritméticas\n",
    "df['sepal minus petal length (cm)'] = df['sepal length (cm)'] - df['petal length (cm)']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También podemos añadir nuevas filas del siguiente modo\n",
    "fila = {\n",
    "        'sepal length (cm)': 5, \n",
    "        'sepal width (cm)': 3,\n",
    "        'petal length (cm)': 2, \n",
    "        'petal width (cm)': 1,\n",
    "        'sepal minus petal length (cm)': 3,\n",
    "       } # No rellenamos todas las celdas para poder filtrar por celdas vacías más adelante\n",
    "\n",
    "df = df.append(fila, ignore_index=True) # Ignoramos el índice porque no estamos indicando ningún nombre para la fila\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para borrar una columna podemos utilizar el método drop según se muestra a continuación\n",
    "df = df.drop('sepal length (cm)', axis=1) # axis indica simplemente que borre una columna, si vale 0 es una fila\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para borrar varias columnas podemos hacerlo mediante una lista de nombres de columnas\n",
    "cols = ['sepal width (cm)', 'petal length (cm)']\n",
    "df = df.drop(cols, axis=1) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del mismo modo, podemos borrar filas mediante el nombre de una fila o una lista de nombres de filas\n",
    "filas = [0, 1, 2, 3, 4]\n",
    "df = df.drop(filas, axis=0) # axis=0 para que borre filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modificar una celda, podemos utilizar iloc\n",
    "df.iloc[0, 0] = 9999.0 # Modifica la celda que se encuentra en la primera fila y primera columna\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y también loc\n",
    "# Modifica la segunda celda de la columna 'sepal minus petal length (cm)'\n",
    "df.loc[6, 'sepal minus petal length (cm)'] = 9999.0 \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente, para cambiar el contenido en más de una celda podemos utilizar la función replace\n",
    "# Esta función ofrece muchísimas opciones, aquí mostramos la más sencilla:\n",
    "df = df.replace(9999.0, 1111.0) # Busca todos los valores 9999.0 y cámbialos por 1111.0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el análisis de datos es muy habitual tener columnas o filas con datos nulos o vacíos, porque su valor desconoce o no es posible calcularlo.\n",
    "\n",
    "`pandas` permite tratar estas situaciones mediante estos métodos:\n",
    "\n",
    "* `isnull()`, `notnull()`: para detectar datos nulos.\n",
    "* `dropna`: para borrar los datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el DataFrame anterior hemos añadido un valor vacío en la columna species, ¿cómo podemos encontrar la fila?\n",
    "cond = df['species'].isnull()\n",
    "\n",
    "df[cond]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el caso de que filas que datos nulos no tengan sentido, podemos borrarlas fácilmente mediante dropna\n",
    "df = df.dropna()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos de nuevo el DataFrame original para seguir con el notebook\n",
    "df = pd.read_csv('./data/04_01_iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupaciones \n",
    "\n",
    "Mediante `pandas` resulta muy sencillo crear agrupaciones de datos y realizar operaciones sobre ellos. Básicamente, las agrupaciones consisten en dos pasos:\n",
    "\n",
    "1. Dividir la tabla de datos en diversos grupos, con el método [`groupby`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html).\n",
    "1. Aplicar una función a los grupos generados, que devolverá un nuevo objeto `Series` o `DataFrame` con el resultado de la función aplicada después de agregar los datos. Habitualmente, utilizaremos el método [`agg`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.agg.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer paso: agrupamos por tipo de especie\n",
    "grupos = df.groupby('species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo paso: aplicamos una función, por ejemplo, la media\n",
    "grupos.agg('mean') # equivale también a escribir .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cualquier función que realice un cálculo sobre los grupos nos servirá, por ejemplo, una función de NumPy\n",
    "df.groupby('species').agg(np.sum) # equivale a escribir .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una función muy utilizada es contar el número de elementos por grupo:\n",
    "df.groupby('species').agg('count') # equivale a escribir .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y aplicar una lista de funciones\n",
    "df.groupby('species').agg(['min', 'max', 'median', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labores de preprocesamiento\n",
    "\n",
    "Uno de los pasos importantes a la hora de hacer un modelo de apreendisaje automático, es el tratamiento de los datos. Para generar los modelo matemáticos, los datos que alimentan el model, tanto en la fase de entrenamiento, de evalución y predicción deben tener un formato que las maquibnas puedan procesar asi como separar los datos en un set de entramiento y un set de evaluación.\n",
    "\n",
    "Para ello, nos podemos valer de la libreria  sklearn Scikit-learn (http://scikit-learn.org/stable/documentation.html). Esta librería es la principal librería que existe para trabajar con Machine Learning, incluye la implementación de un gran número de algoritmos de aprendizaje. La podemos utilizar para clasificaciones, extraccion de características, regresiones, agrupaciones, reducción de dimensiones, selección de modelos, o preprocesamiento. Posee una API que es consistente en todos los modelos y se integra muy bien con el resto de los paquetes científicos que ofrece Python. Esta librería también nos facilita las tareas de evaluación, diagnostico y validaciones cruzadas ya que nos proporciona varios métodos de fábrica para poder realizar estas tareas en forma muy simple.\n",
    "\n",
    "Supongamos que queremos generar un modelo que con los datos de iris data set que sea capaz de clasificar cada una de las especies. \n",
    "\n",
    "\n",
    "Para ello hemso de hacer un procesado de los datos a fin de que puedan ser usados por un modelo para tal fin.\n",
    "\n",
    "\n",
    "Los modelos matemáticos (en su mayoría)  no acepta cadenas como parámetros de las funciones, todo deben de ser números. Para ello, nos podemos valer del objeto sklearn.preprocessing.LabelEncoder, que nos transforma automáticamente las cadenas a números. La forma en que se utiliza es la siguiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos de nuevo el DataFrame original para seguir con el notebook\n",
    "df = pd.read_csv('./data/04_01_iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['species'])\n",
    "df['species_cod'] = le.transform(df['species'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform(df.species_cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.species_cod.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\n",
    "Como podéis observar, primero se crea el LabelEncoder y luego se \"entrena\" mediante el método fit. Para un LabelEncoder, \"entrenar\" el modelo es decidir el mapeo que vimos anteriormente, en este caso:\n",
    "2\n",
    "​\n",
    "3\n",
    "   * Iris-setosa -> 0\n",
    "4\n",
    "   * Iris-versicolor -> 1\n",
    "5\n",
    "   * Iris-virginica -> 2\n",
    "6\n",
    "​\n",
    "7\n",
    "Una vez entrenado, utilizando el método transform del LabelEncoder, podremos transformar cualquier ndarray que queramos (hubiéramos tenido un error si alguna de las etiquetas de test no estuviera en train). Esta estructura (método fit más método transform o predict) se repite en muchos de los objetos de scikit-learn.\n",
    "8\n",
    "​\n",
    "9\n",
    "Hay muchas más tareas de preprocesamiento que se pueden hacer en scikit-learn. **Consulta el paquete sklearn.preprocessing**.\n",
    "10\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos los datos\n",
    "\n",
    "Separamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = df.drop(['species','species_cod'],axis=1)\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_target = df.species_cod\n",
    "iris_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos los Datos.... Entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los Datos.... Entrenamiento y test\n",
    "#?  train_test_split()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_target,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=191,\n",
    "                                                    shuffle =True)\n",
    "\n",
    "print('Set de datos para Entrenamiento =',len(X_train))\n",
    "print('Set de datos para Test',len(X_test))\n",
    "print('Total',len(X_test)+len(X_train))\n",
    "print('Data Shape=',X_test.shape)\n",
    "print('Target Shape =',y_test.shape)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora Ustedes..... !!!!\n",
    "\n",
    "**EJERCICIO 1**. \n",
    "\n",
    "Primero de todo, carga en la variable `df` el fichero con los datos de las flores Iris en formato CSV que se encuentra en el directorio * **'./data/04_01_iris.csv'**. \n",
    "\n",
    "Después, muestra el contenido únicamente de las primeras 15 filas de las columnas `sepal length (cm)`, `sepal width (cm)` y `species` del dataframe `df`.\n",
    "\n",
    "\n",
    "**EJERCICIO 2**. \n",
    "\n",
    "Muestra el contenido de la celda de la quinta fila y la cuarta columna del dataframe `df` numéricamente. Recuerda que empezamos a contar desde cero:\n",
    "\n",
    "** EJERCICIO 3**.\n",
    "\n",
    "De nuestro DataFrame de flores Iris que tenemos en la variable df, selecciona todas aquellas filas que sean setosa y el largo de su sépalo sea mayor que 5,5 cm o bien el largo de su pétalo sea inferior a 1,3 cm.\n",
    "\n",
    "**EJERCICIO 4**.\n",
    "\n",
    "Ahora, filtra todas aquellas filas de tipo versicolor, en las que el largo del sépalo sea mayor o igual a 5 cm y el largo del pétalo esté entre 3 y 3,5 cm inclusive.\n",
    "\n",
    "**EJERCICIO 5**.\n",
    "\n",
    "Después, muestra la media y desviación estándar del ancho del sépalo de las flores Virginica.\n",
    "\n",
    "**Pista**: las funciones mean() y std() devuelven la media y desviación estándar. Puedes utilizar `print(a, b)` para imprimir los dos valores en la misma línea si quieres.\n",
    "\n",
    "\n",
    "**EJERCICIO 6**. \n",
    "\n",
    "Utilizando el mismo dataset que tenemos cargado en la variable `df`, calcula el sumatorio de todos los valores al cuadrado de todas las columnas (ancho y largo de los sépalos y ancho y largo de los pétalos) para cada especie.\n",
    "\n",
    "**Pista**: deberás declarar una nueva función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucion Ej 1\n",
    "\n",
    "df = pd.read_csv('./data/04_01_iris.csv')\n",
    "cols = ['sepal length (cm)', 'sepal width (cm)', 'species']\n",
    "df[cols].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución Ej 2\n",
    "\n",
    "df.iloc[4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución Ej 3\n",
    "cond1 = df['species'] == 'setosa'\n",
    "cond2 = df['sepal length (cm)'] > 5.5\n",
    "cond3 = df['petal length (cm)'] < 1.3\n",
    "\n",
    "df[cond1 & (cond2 | cond3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución Ej 4\n",
    "cond1 = df['species'] == 'versicolor'\n",
    "cond2 = df['sepal length (cm)'] >= 5\n",
    "cond3 = df['petal length (cm)'] >= 1.3\n",
    "cond4 = df['petal length (cm)'] <= 3.5\n",
    "\n",
    "df[cond1 & cond2 & cond3 & cond4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución Ej 5\n",
    "\n",
    "cond = df['species'] == 'virginica'\n",
    "\n",
    "df_virginica = df[cond]\n",
    "\n",
    "print(df_virginica['sepal width (cm)'].mean(), df_virginica['sepal width (cm)'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución Ej 6\n",
    "\n",
    "def func(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "df.groupby('species').agg(func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
