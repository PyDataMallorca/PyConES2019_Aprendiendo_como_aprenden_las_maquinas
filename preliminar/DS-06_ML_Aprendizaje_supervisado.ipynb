{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como acabamos de comentar, el objetivo principal de un algoritmo de aprendizaje supervisado sería el de usar un conjunto de datos para obtener un modelo el cual tomará un *feature vector* **x** como entrada y producirá una información de salida que nos permitirá deducir la etiqueta para ese *feature vector*.\n",
    "\n",
    "Se puede dividir en dos grandes partes, la regresión y la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un algoritmo de aprendizaje supervisado puede estar basado en aprendizaje de modelo (*model-based*) o basado en aprendizaje de instancia (instance-based*).\n",
    "\n",
    "Los algoritmos de aprendizaje basados en modelo son aquellos que se basan en los datos de entrada para entrenar un modelo que tiene unos parámetros que se aprenden a partir de los datos. Una vez aprendidos estos parámetros se pueden desechar los datos de entrada.\n",
    "\n",
    "Los algoritmos de aprendizaje basados en instancia usan el conjunto completo de los datos como modelo. El ejemplo más claro es el KNN que veremos a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje puede ser superficial (*shallow learning*) o profundo (*deep learning*). El primero, *shallow learning* aprende los parámetros directamente de los rasgos (*features*) de los ejemplos de entrenamiento. El segundo, *deep learning*, la mayoría de los parámetros del modelo no se aprenden directamente de los rasgos (*features*) de los ejemplos de entrada, se aprenden de las salidas de las capas intermedias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos comentado alguna vez, nuestro objetivo no va a ser obtener el modelo mejor ajustado, nuestro objetivo va a ser obtener el modelo que mejor generalice.\n",
    "\n",
    "Queremos construir un modelo basado en los datos de entrenamiento y después poder hacer predicciones precisas cuando tengamos nuevos datos de entrada nunca vistos antes. Si somos capaces de conseguir lo anterior diremos que nuestro modelo generaliza. Añadiendo a lo primero, nuestro objetivo va a ser el modelo que mejor generalice dando los resultados más precisos posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, nuestros datos de entrada los dividiremos en varias partes, la primera parte se usará para entrenar el modelo mientras que otras partes se usarán para ver si el modelo da buenos resultados en esos datos nunca vistos.\n",
    "\n",
    "Por supuesto, hemos de procurar que los datos de entrenamiento y de prueba sean ambos representativos y sean bastante similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobreajuste e infrajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nosotros ajustamos nuestro modelo muy bien a nuestros datos de entrenamiento el modelo quizá sea capaz de aprender \"demasiado\" de los datos y, luego, no sea capaz de generalizar correctamente cuando se encuentre nuevos casos. Cuando nos encontramos en una situación así es muy probable que estemos cometiendo un sobreajuste.\n",
    "\n",
    "Por ejemplo, con los siguientes datos:\n",
    "\n",
    "| Sexo | Edad | Número de hijos | Estado civil | Posee moto |\n",
    "|-|-|-|-|-|\n",
    "| Hombre | 56 | 3 | Casado | No |\n",
    "| Hombre | 45 | 0 | Divorciado | Si |\n",
    "| Mujer | 33 | 3 | Casado | No |\n",
    "| Mujer | 45 | 1 | Divorciado | No |\n",
    "| Hombre | 45 | 1 | Divorciado | Si |\n",
    "| Hombre | 45 | 0 | Soltero | Si |\n",
    "| Hombre | 45 | 1 | Casado | Si |\n",
    "\n",
    "Nuestro algoritmo podría decir que todos los hombres por debajo de 56 años y con menos de 2 hijos e independientemente de su estado civil poseen moto.\n",
    "\n",
    "Si metemos un nuevo caso, ¿creéis que acertaría?, ¿sería mejor entrenar el modelo con 500 datos?, ¿con más datos crees que el modelo sería \"todos los hombres por debajo de 56 años y con menos de 2 hijos e independientemente de su estado civil poseen moto\"?,...\n",
    "\n",
    "Otro extremos podría ser un modelo más simple, si tienes 56 años o más no posees una moto.\n",
    "\n",
    "En este segundo ejemplo, ¿crees que el modelo acertaría mayoritariamente?, ¿tendría muchos falsos positivos?, ¿tendría muchos falsos negativos?,...\n",
    "\n",
    "Deberíamos procurar que nuestro modelo sea simple pero no excesivamente simple. Un modelo más simple generaliza mejor que un modelo extremadamente complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La complejidad de nuestro modelo está intimamente relacionada a la variación de entradas en nuestros datos de entrenamiento. Cuando más variedad haya en nuestros datos de entrada más complejo podrá ser el modelo que obtengamos sin caer en un sobreajuste. Normalmente, obtener más datos de entrada debería llevar a disponer de mayor variedad pero hay que tener cuidado y comprobar que esto sea así ya que hay ocasiones en que mayor número de datos no implica necesariamente aumentar la variedad de los mismos ya que podríamos estar introduciendo duplicados o valores muy similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La única forma de saber si nuestro modelo funciona correctamente seria evaluarlo en los datos de prueba.\n",
    "\n",
    "![Over y underfitting](./imgs/09_Over_under_fitting.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente no nos vale decir que \"creemos\" que nuestro algoritmo generaliza bien, necesitamos una serie de métricas para poder evaluarlo.\n",
    "\n",
    "También hemos de saber qué es lo que estamos midiendo. Por ejemplo, si nuestro problema es evitar dar falsos negativos en una prueba diagnóstica médica no nos podemos permitir el lujo de que esto paso como sí que nos lo podríamos permitir en la detección de SPAM donde ante la duda el fallo no sería muy grave.\n",
    "\n",
    "### Datos desnivelados\n",
    "\n",
    "Conocidos en inglés como *imbalanced datasets*. Por ejemplo, en un caso de clasificación binaria, cuando tenemos muchísimos casos de una clase, por ejemplo NO SPAM y muy pocos casos de otr clase, por ejemplo SPAM, hemos de tener especial cuidado al medir lo bueno que es nuestro algoritmo.\n",
    "\n",
    "Por ejemplo, si tengo 100 correos donde 99 son correos buenos y uno es SPAM. Si decimos que todos los correos son siempre buenos tenemos una precisión del 99% cuando en realidad nuestro algoritmo no es capaz de detectar el SPAM.\n",
    "\n",
    "Para resolver esto algunos algoritmos me pueden permitir dar diferentes pesos a las diferentes clases. Otra forma sería usando un *oversampling*, repetir los datos menos frecuentes para que haya más presencia. Otra forma sería usando un *undersampling*, eliminar datos de las clases sobrerrepresentadas,...\n",
    "\n",
    "### Métricas en clasificación binaria\n",
    "\n",
    "Se pueden extender fácilmente a la clasificación multiclase.\n",
    "\n",
    "Volviendo al caso del cáncer. Se pueden dar los siguientes casos\n",
    "\n",
    "| - | Predecimos cáncer | Predecimos NO cáncer |\n",
    "|-|-|-|\n",
    "| Tiene cáncer | TP | FN |\n",
    "| NO tiene cáncer | FP | TN |\n",
    "\n",
    "Lo anterior se conoce como Matriz de confusión y muestra un resumen de nuestros resultados. A partir de la misma podemos obtener:\n",
    "\n",
    "* **Accuracy** mide el número de aciertos dividido entre el número total de muestras:\n",
    "\n",
    "$$ Accuracy = \\frac{TP+TN}{TP+FP+TN+FN} $$\n",
    "\n",
    "* **Precision** mide cuantos de los datos predichos como positivos son realmente positivos. Se usa cuando el objetivo es limitar el número de falsos positivos. También se conoce como *Positive Predictive Value (PPV)*:\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP+FP} $$\n",
    "\n",
    "* **Recall** mide cuantos de los datos predichos como positivos serían capturados por las predicciones positivas. Se usa cuando es importante evitar falsos negativos. También se conoce como *sensitivity*, *hit rate* o *True Positive Rate (TPR):\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP+FN} $$\n",
    "\n",
    "* **f-score** o **f-measure** sirve para resumir tanto la **Precision** como el **Recall**. Mide la media armónica de la **Precision** y el **Recall**:\n",
    "\n",
    "$$ f-score = 2 · \\frac{Precision · Recall}{Precision+Recall} $$\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "Existen muchas más métricas que veremos luego de forma práctica cuando vayamos analizando algoritmos.\n",
    "\n",
    "## Métricas en regresión\n",
    "\n",
    "Estás quizá sean más conocidas en nuestro día a día.\n",
    "\n",
    "* MSE, error cuadrático medio. Se aplica a los datos de entrenamiento y a los datos de prueba. Un MSE bajo en los datos de entrenamiento y un MSE considerablemente más alto en los datos de prueba indicarán un sobreajuste.\n",
    "\n",
    "* $R^2$, coeficiente de determinación, es una medida de la bondad de una predicción para un modelo de regresión. El valor se encuentra entre 0 y 1 donde 1 indica una predicción perfecta y 0 indica que el model solo predice el promedio de los datos de entrada de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos que usaremos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar datos muy sencillos, con pocas dimensiones, para que sean fáciles de visualizar y puedan ser bastante instructivos.\n",
    "\n",
    "Para complementar usaremos datos de casos reales que se incluyen en `scikit-learn`. \n",
    "\n",
    "* Uno de los conjuntos de datos reales que usaremos es el *Wisconsin Breast Cancer dataset* que muestra registros clínicos de medidas de tumores de cáncer de pecho. Cada tumos está etiquetado como \"benigno\" cuando el cáncer no es dañino o \"maligno\" para tumores cancerígenos.\n",
    "\n",
    "* Otro conjunto de datos será el *Boston Housing dataset*. Los datos contienen información de precios de viviendas en diferentes barriadas así como la tasa de crimen, proximidad al rio Charles, facilidad de acceso a una autopista,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirad un poco los datos de \"Boston\" y de \"Cancer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización / estandarización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para algunos algoritmos tiene sentido \"modificar\" los datos. Por ejemplo, si medimos distancias y una dimensión corresponde a una variable que es un orden de magnitud superior que la variable en otra dimensión podemos tener el problema de que le estemos dando más importancia a la primera dimensión y tenga mayor efecto en los cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plots import plot_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico anterior vemos que en los datos originales los valores de X varían entre 10 y 15 mientras que los valores de Y varían entre 0 y 10.\n",
    "\n",
    "Para evitar esto podemos escalar y/o desplazar (normalizar o estandarizar) los datos antes de entrenar nuestro algoritmo.\n",
    "\n",
    "La normalización la podemos hacer de varias formas. Una podría ser así:\n",
    "\n",
    "$$ \\bar{x}^{(j)} = \\frac{x^{(j)} - min^{(j)}}{max^{(j)}- min^{(j)}} $$\n",
    "\n",
    "Y tendríamos valores entre 0 y 1. Se podría hacer de otras formas y tener valores, por ejemplo, entre -1 y 1.\n",
    "\n",
    "La estandarización, normalmente, se hace así:\n",
    "\n",
    "$$ \\hat{x}^{(j)} = \\frac{x^{(j)} - \\mu^{(j)}}{\\sigma^{(j)}} $$\n",
    "\n",
    "El conjunto de valores tendría media 0 y desviación estándar 1.\n",
    "\n",
    "¿Cuándo normalizar y cuando estandarizar?\n",
    "\n",
    "* en la práctica, los algoritmos de aprendizaje no supervisado se suelen beneficiar más de la estandarización.\n",
    "\n",
    "* también sería preferible la estandarización para una *feature* si sus valores se distribuyen normalmente.\n",
    "\n",
    "* si existen *outliers* en los datos la estandarización sería preferible ya que una normalización podría comprimir la mayoría de los datos en un rango muy pequeño.\n",
    "\n",
    "* en otros casos sería preferible una normalización.\n",
    "\n",
    "Hay diferentes formas de hacer esto y el cómo hacerlo dependerá un poco de los datos que tengamos. Luego lo veremos más en detalle si da tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de datos perdidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestros datos rara vez van a ser perfectos y normalmente habrá datos que tendremos que filtrar, datos que se han medido mal, datos que no se han medido,...\n",
    "\n",
    "Las cosas más típicas que podemos hacer serían:\n",
    "\n",
    "* Si tenemos datos de sobra podemos eliminar esos *feature vector* que tienen alguna *feature* con datos incorrectos.\n",
    "\n",
    "* Podemos usar un algoritmo que sepa lidiar con estos datos perdidos y sea capaz de tenerlos en cuenta sin introducir errores artificiales. Esto dependerá del algoritmo y biblioteca que estemos usando.\n",
    "\n",
    "* Podemos rellenar los datos perdidos para no perder información. Hay varias formas de relleno:\n",
    " * usando el promedio de la *feature*\n",
    " * rellenando usando un valor que se encuentre fuera del rando normal de valores. La idea aqui es que sea el algoritmo el que aprenda cómo lidiar con esos datos perdidos de alguna forma\n",
    " * rellenando con un valor que esté en medio del rango de valores. De esta forma se espera que al estar en el medio no afectará a los resultados globales de forma importante.\n",
    " * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección del algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta no es una tarea sencilla y no se basará solo en la precisión que podamos llegar a obtener con determinado algoritmo.\n",
    "\n",
    "Veamos cosas a tener en cuenta:\n",
    "\n",
    "* Explicabilidad: A veces puede ser más interesante que el algoritmo sea fácil de interpretar y que no sea una caja negra.\n",
    "\n",
    "* ¿Podemos permitirnos el lujo de tener todos los datos en memoria? Nuestros recursos computacionales nos pueden limitar a la hora de elegir un algoritmo u otro.\n",
    "\n",
    "* Número de datos y *features*. Dependiendo del algoritmo igual no es capaz de manejar una gran dimensionalidad o no escala bien cuando el conjunto de datos es muy grande.\n",
    "\n",
    "* ¿Los datos son categóricos o numéricos? Dependiendo de esto algunos algoritmos serán más adecuados que otros.\n",
    "\n",
    "* No linealidad de los datos. Si los datos son lineales podemos elegir modelos lineales más sencillos.\n",
    "\n",
    "* Tiempo de entrenamiento.\n",
    "\n",
    "* Tiempo de predicción.\n",
    "\n",
    "* ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
