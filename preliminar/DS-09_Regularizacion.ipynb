{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentes algoritmos usan diferentes formas de medir lo que significa \"ajustar correctamente los datos de entrenamiento\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> “Everything should be made simple as possible, but not simpler – Albert Einstein”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regularización es un tèrmino que comprende diferentes métodos que fuerzan a los algoritmos de aprendizaje a crear un modelo  menos complejo. En la práctica, esto puede llevar a menudo a un sesgo ligeramente mayor pero reduce de forma significativa la varianza. Este término se conoce como el *bias-variance tradeoff*.\n",
    "\n",
    "![bias-variance tradeoff](./imgs/10_bias-variance.png)\n",
    "\n",
    "[Fuente - From Understanding the Bias-Variance Tradeoff, por Scott Fortmann-Roe.](http://scott.fortmann-roe.com/docs/BiasVariance.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos que nuestro modelo sea lo más simple posible pero no tan simple. Es por ello que deberemos de probar diferentes cosas para llegar a un óptimo:\n",
    "\n",
    "![model complexity](./imgs/11_model-complex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A medida que añadimos más y más información a nuestro modelo estamos aumentando su complejidad. Este suele llevar a un incremento de la varianza mejorando nuestro sesgo pero esto conduce, también, a potencial sobreajuste. Por tanto, en la práctica debemos encontrar un óptimo donde no se nos dispare nada (sesgo, varianza, complejidad) y que nuestro modelo generalice bien. Pero no hay una forma de hacer esto que sea totalmente objetiva y analítica. \n",
    "\n",
    "¿Cómo podemos lidiar con estas cosas?\n",
    "\n",
    "Si nuestro modelo funciona mal podemos añadirle mayor información. A medida que añadimos más *features* a nuestro modelo su complejidad aumenta y debería ayudarnos a reducir el sesgo pero hay que hacerlo con cabeza para que no lleguemos a un sobreajuste.\n",
    "\n",
    "Basicamente tenemos dos formas:\n",
    "\n",
    "* Reducir la complejidad del modelo.\n",
    "\n",
    "* Usar regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización\n",
    "\n",
    "Los dos tipos de regularización más ampliamente usados se llaman regularización L1 y regularización L2. La idea es bastante simple, para crear un modelo regularizado modificamos la función objetivo añadiendo un término de penalización cuyo valor es más alto cuando el modelo es más complejo.\n",
    "\n",
    "Por simplicidad, vamos a ver esto de la regularización usando la regresion lineal. El mismo principio puede ser aplicado a una amplia variedad de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a recordar la función objetivo a minimizar de la regresión lineal:\n",
    "\n",
    "$$ f(w, b) = \\frac{1}{N}\\sum_{i=1}^{N}(y_i - (w*x_i+b))^2 $$\n",
    "\n",
    "A la anterior función le metemos un término que penaliza la función de pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función objetivo regularizada usando el tipo L1 sería de la siguiente forma:\n",
    "\n",
    "$$ f(w, b) = \\lambda|\\textbf{w}|+\\frac{1}{N}\\sum_{i=1}^{N}(y_i - (w*x_i+b))^2 $$\n",
    "\n",
    "donde $ |\\textbf{w}| = \\sum_{j=1}^{D}|w_{j}| $, es la suma del valor absoluto de los pesos\n",
    "y $ \\lambda $ es un hiperparámetro que controla la importancia de la regularización.\n",
    "\n",
    "Si $ \\lambda = 0 $ nos encontramos en el caso de la regresión lineal. En cambio, si $ \\lambda >> 0 $ el algoritmo de aprendizaje intentará que todos los $ w_j $ estén muy cerca de 0 o siendo 0 y el modelo puede acabar siendo muy simple y puede acabar en un subajuste (*underfitting*). Tu trabajo va a ser ajustar correctamente este hiperparámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, una función objetivo regularizada usando el tipo L2 sería de la siguiente forma:\n",
    "\n",
    "$$ f(w, b) = \\lambda||\\textbf{w}||^2 +\\frac{1}{N}\\sum_{i=1}^{N}(y_i - (w*x_i+b))^2 $$\n",
    "\n",
    "donde $ ||\\textbf{w}|| = \\sum_{j=1}^{D}(w_{j})^2 $, es la suma del valor al cuadrado de los pesos de los pesos\n",
    "y $ \\lambda $ sigue siendo un hiperparámetro que controla la importancia de la regularización.\n",
    "\n",
    "Al igual que antes, si $ \\lambda = 0 $ nos encontramos en el caso de la regresión lineal. En cambio, si $ \\lambda >> 0 $ el algoritmo de aprendizaje intentará que todos los $ w_j $ estén muy cerca de 0 (pero no siendo cero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia básica entre la regularización L1 y la regularización L2 es que en el caso de la primera varios pesos acaban siendo cero ayudando a mostrar qué *features* van a ser importantes en el ajuste. Nos permite hacer *feature selection* lo que permite que nuestro modelo sea más explicable por la simplificación. El L2 generaliza más y suele dar mejores resultados. L2 también nos permite resolverlo usando Gradiente Descendiente ya que es diferenciable.\n",
    "\n",
    "Se pueden combinar las regularizaciones L1 y L2 (por ejemplo, *elastic net*. En la literatura se puede encontrar que la regularización L1 se le llama también **Lasso** y la regularización L2 se le llama también **Ridge**. Estas regularizaciones se usan ampliamente en modelos lineales pero también en redes neuronales y otros tipos de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen otros tipos de regularizaciones que no vamos a ver como *dropout*, *batchnormalization*, *data augmentation* o *early stopping*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobreajuste en la regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a abonar un poco el terreno para nuestro siguiente capítulo usando un conjunto de datos con muchas más *features*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lib.datasets import load_extended_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_extended_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tenemos un dataset con 506 ejemplos (filas) y 104 *features* (columnas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[INCISO]** En `scikit-learn` muchos métodos de los modelos normalmente devuelven `self` por lo que llamar a `LinearRegression` e inmediatamente después a su método `fit` nos sigue devolviendo el modelo pero ya ajustado. Lo anterior es equivalente a hacer:\n",
    "\n",
    "```python\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)  ## Esto devuelve self (el propio objeto)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cómo se comporta nuestro modelo con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guau, no va nada mal...\n",
    "\n",
    "A ver qué tal se comporta con los datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaya, este valor es mucho más bajo que para los datos de entrenamiento. \n",
    "\n",
    "¿Qué puede estar pasando?\n",
    "\n",
    "¿Cómo podemos resolver esto?\n",
    "\n",
    "¿De qué iba este capítulo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Pasamos al siguiente capítulo y resolvemos este desaguisado?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
